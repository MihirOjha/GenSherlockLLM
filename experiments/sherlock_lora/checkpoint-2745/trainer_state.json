{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.0,
  "eval_steps": 500,
  "global_step": 2745,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0546448087431694,
      "grad_norm": 0.6343225240707397,
      "learning_rate": 9.821493624772314e-05,
      "loss": 3.7707,
      "step": 50
    },
    {
      "epoch": 0.1092896174863388,
      "grad_norm": 0.743842601776123,
      "learning_rate": 9.639344262295082e-05,
      "loss": 3.6368,
      "step": 100
    },
    {
      "epoch": 0.16393442622950818,
      "grad_norm": 0.8791216611862183,
      "learning_rate": 9.45719489981785e-05,
      "loss": 3.5714,
      "step": 150
    },
    {
      "epoch": 0.2185792349726776,
      "grad_norm": 0.7040669322013855,
      "learning_rate": 9.27504553734062e-05,
      "loss": 3.5335,
      "step": 200
    },
    {
      "epoch": 0.273224043715847,
      "grad_norm": 0.7131112217903137,
      "learning_rate": 9.092896174863389e-05,
      "loss": 3.5068,
      "step": 250
    },
    {
      "epoch": 0.32786885245901637,
      "grad_norm": 0.850111722946167,
      "learning_rate": 8.910746812386157e-05,
      "loss": 3.4464,
      "step": 300
    },
    {
      "epoch": 0.3825136612021858,
      "grad_norm": 0.8390820622444153,
      "learning_rate": 8.728597449908927e-05,
      "loss": 3.4608,
      "step": 350
    },
    {
      "epoch": 0.4371584699453552,
      "grad_norm": 0.7159180045127869,
      "learning_rate": 8.546448087431695e-05,
      "loss": 3.4801,
      "step": 400
    },
    {
      "epoch": 0.4918032786885246,
      "grad_norm": 0.8889944553375244,
      "learning_rate": 8.364298724954463e-05,
      "loss": 3.4454,
      "step": 450
    },
    {
      "epoch": 0.546448087431694,
      "grad_norm": 0.826270580291748,
      "learning_rate": 8.182149362477231e-05,
      "loss": 3.3995,
      "step": 500
    },
    {
      "epoch": 0.6010928961748634,
      "grad_norm": 0.8471820950508118,
      "learning_rate": 8e-05,
      "loss": 3.4361,
      "step": 550
    },
    {
      "epoch": 0.6557377049180327,
      "grad_norm": 0.858573317527771,
      "learning_rate": 7.817850637522769e-05,
      "loss": 3.3949,
      "step": 600
    },
    {
      "epoch": 0.7103825136612022,
      "grad_norm": 0.7570732831954956,
      "learning_rate": 7.635701275045538e-05,
      "loss": 3.4643,
      "step": 650
    },
    {
      "epoch": 0.7650273224043715,
      "grad_norm": 0.9071458578109741,
      "learning_rate": 7.453551912568306e-05,
      "loss": 3.3775,
      "step": 700
    },
    {
      "epoch": 0.819672131147541,
      "grad_norm": 0.856846272945404,
      "learning_rate": 7.271402550091076e-05,
      "loss": 3.434,
      "step": 750
    },
    {
      "epoch": 0.8743169398907104,
      "grad_norm": 0.773163378238678,
      "learning_rate": 7.089253187613844e-05,
      "loss": 3.4511,
      "step": 800
    },
    {
      "epoch": 0.9289617486338798,
      "grad_norm": 0.7270745635032654,
      "learning_rate": 6.907103825136612e-05,
      "loss": 3.4047,
      "step": 850
    },
    {
      "epoch": 0.9836065573770492,
      "grad_norm": 1.0272057056427002,
      "learning_rate": 6.72495446265938e-05,
      "loss": 3.4409,
      "step": 900
    },
    {
      "epoch": 1.0382513661202186,
      "grad_norm": 0.8776835203170776,
      "learning_rate": 6.54280510018215e-05,
      "loss": 3.4255,
      "step": 950
    },
    {
      "epoch": 1.092896174863388,
      "grad_norm": 0.8647314310073853,
      "learning_rate": 6.360655737704918e-05,
      "loss": 3.3927,
      "step": 1000
    },
    {
      "epoch": 1.1475409836065573,
      "grad_norm": 0.9348195791244507,
      "learning_rate": 6.178506375227687e-05,
      "loss": 3.3619,
      "step": 1050
    },
    {
      "epoch": 1.2021857923497268,
      "grad_norm": 0.8437890410423279,
      "learning_rate": 5.9963570127504555e-05,
      "loss": 3.4223,
      "step": 1100
    },
    {
      "epoch": 1.2568306010928962,
      "grad_norm": 0.7880025506019592,
      "learning_rate": 5.814207650273224e-05,
      "loss": 3.3662,
      "step": 1150
    },
    {
      "epoch": 1.3114754098360657,
      "grad_norm": 0.7906590104103088,
      "learning_rate": 5.6320582877959924e-05,
      "loss": 3.3918,
      "step": 1200
    },
    {
      "epoch": 1.366120218579235,
      "grad_norm": 0.8642391562461853,
      "learning_rate": 5.449908925318762e-05,
      "loss": 3.3515,
      "step": 1250
    },
    {
      "epoch": 1.4207650273224044,
      "grad_norm": 0.8327211737632751,
      "learning_rate": 5.26775956284153e-05,
      "loss": 3.3919,
      "step": 1300
    },
    {
      "epoch": 1.4754098360655736,
      "grad_norm": 0.8085357546806335,
      "learning_rate": 5.085610200364299e-05,
      "loss": 3.3946,
      "step": 1350
    },
    {
      "epoch": 1.530054644808743,
      "grad_norm": 0.8054250478744507,
      "learning_rate": 4.9034608378870676e-05,
      "loss": 3.413,
      "step": 1400
    },
    {
      "epoch": 1.5846994535519126,
      "grad_norm": 0.9546823501586914,
      "learning_rate": 4.7213114754098365e-05,
      "loss": 3.4183,
      "step": 1450
    },
    {
      "epoch": 1.639344262295082,
      "grad_norm": 0.9311498403549194,
      "learning_rate": 4.539162112932605e-05,
      "loss": 3.4075,
      "step": 1500
    },
    {
      "epoch": 1.6939890710382515,
      "grad_norm": 0.8186563849449158,
      "learning_rate": 4.3570127504553734e-05,
      "loss": 3.4088,
      "step": 1550
    },
    {
      "epoch": 1.748633879781421,
      "grad_norm": 0.8904168009757996,
      "learning_rate": 4.174863387978142e-05,
      "loss": 3.4174,
      "step": 1600
    },
    {
      "epoch": 1.8032786885245902,
      "grad_norm": 0.8965431451797485,
      "learning_rate": 3.992714025500911e-05,
      "loss": 3.4038,
      "step": 1650
    },
    {
      "epoch": 1.8579234972677594,
      "grad_norm": 0.7682995200157166,
      "learning_rate": 3.81056466302368e-05,
      "loss": 3.4075,
      "step": 1700
    },
    {
      "epoch": 1.9125683060109289,
      "grad_norm": 0.8588718771934509,
      "learning_rate": 3.6284153005464486e-05,
      "loss": 3.3646,
      "step": 1750
    },
    {
      "epoch": 1.9672131147540983,
      "grad_norm": 0.7722220420837402,
      "learning_rate": 3.446265938069217e-05,
      "loss": 3.3621,
      "step": 1800
    },
    {
      "epoch": 2.021857923497268,
      "grad_norm": 0.8560059070587158,
      "learning_rate": 3.2641165755919855e-05,
      "loss": 3.3548,
      "step": 1850
    },
    {
      "epoch": 2.0765027322404372,
      "grad_norm": 0.9398171305656433,
      "learning_rate": 3.0819672131147544e-05,
      "loss": 3.3728,
      "step": 1900
    },
    {
      "epoch": 2.1311475409836067,
      "grad_norm": 0.8381726741790771,
      "learning_rate": 2.8998178506375228e-05,
      "loss": 3.3657,
      "step": 1950
    },
    {
      "epoch": 2.185792349726776,
      "grad_norm": 0.9666375517845154,
      "learning_rate": 2.7176684881602916e-05,
      "loss": 3.3644,
      "step": 2000
    },
    {
      "epoch": 2.240437158469945,
      "grad_norm": 0.9593695402145386,
      "learning_rate": 2.53551912568306e-05,
      "loss": 3.3693,
      "step": 2050
    },
    {
      "epoch": 2.2950819672131146,
      "grad_norm": 0.8066177368164062,
      "learning_rate": 2.353369763205829e-05,
      "loss": 3.4038,
      "step": 2100
    },
    {
      "epoch": 2.349726775956284,
      "grad_norm": 0.8942046165466309,
      "learning_rate": 2.1712204007285974e-05,
      "loss": 3.4065,
      "step": 2150
    },
    {
      "epoch": 2.4043715846994536,
      "grad_norm": 0.924814760684967,
      "learning_rate": 1.9890710382513662e-05,
      "loss": 3.3482,
      "step": 2200
    },
    {
      "epoch": 2.459016393442623,
      "grad_norm": 0.9774720072746277,
      "learning_rate": 1.806921675774135e-05,
      "loss": 3.3818,
      "step": 2250
    },
    {
      "epoch": 2.5136612021857925,
      "grad_norm": 0.8460582494735718,
      "learning_rate": 1.6247723132969038e-05,
      "loss": 3.365,
      "step": 2300
    },
    {
      "epoch": 2.5683060109289615,
      "grad_norm": 0.8552249073982239,
      "learning_rate": 1.4426229508196722e-05,
      "loss": 3.4068,
      "step": 2350
    },
    {
      "epoch": 2.6229508196721314,
      "grad_norm": 0.9925402998924255,
      "learning_rate": 1.2604735883424409e-05,
      "loss": 3.3458,
      "step": 2400
    },
    {
      "epoch": 2.6775956284153004,
      "grad_norm": 0.8998821377754211,
      "learning_rate": 1.0783242258652095e-05,
      "loss": 3.3577,
      "step": 2450
    },
    {
      "epoch": 2.73224043715847,
      "grad_norm": 0.9328887462615967,
      "learning_rate": 8.961748633879782e-06,
      "loss": 3.3246,
      "step": 2500
    },
    {
      "epoch": 2.7868852459016393,
      "grad_norm": 0.8873849511146545,
      "learning_rate": 7.140255009107469e-06,
      "loss": 3.4094,
      "step": 2550
    },
    {
      "epoch": 2.841530054644809,
      "grad_norm": 0.9229593276977539,
      "learning_rate": 5.318761384335155e-06,
      "loss": 3.403,
      "step": 2600
    },
    {
      "epoch": 2.8961748633879782,
      "grad_norm": 0.9144490361213684,
      "learning_rate": 3.4972677595628415e-06,
      "loss": 3.4219,
      "step": 2650
    },
    {
      "epoch": 2.9508196721311473,
      "grad_norm": 0.941926896572113,
      "learning_rate": 1.6757741347905285e-06,
      "loss": 3.3596,
      "step": 2700
    }
  ],
  "logging_steps": 50,
  "max_steps": 2745,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 1131074576179200.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
